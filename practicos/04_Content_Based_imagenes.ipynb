{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-maVVHeUxcgl"
      },
      "source": [
        "# Práctico Content-based (Imágenes)\n",
        "\n",
        "IIC-3633, PUC Chile\n",
        "\n",
        "**Profesor:** Denis Parra\n",
        "\n",
        "**Alumno:** `ESCRIBIR TU NOMBRE AQUI`\n",
        "\n",
        "En esta actividad trabajaremos con un recomendador de ropa basado netamente en las imagenes más similares extrayendo features con redes neuronales convolucionales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNDMg4jlgrfi"
      },
      "outputs": [],
      "source": [
        "from keras.applications import vgg16, vgg19, ResNet50\n",
        "from tensorflow.keras.utils import load_img,img_to_array\n",
        "from keras.models import Model\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUF85Rw9llZm"
      },
      "source": [
        "En esta sección se trabajará con modelos pre-entrenados de redes convolucionales (CNN) que extraen caracteristicas visuales de las imagenes.\n",
        "\n",
        "![Ejemplo de red convolucional](https://www.researchgate.net/publication/326658868/figure/fig3/AS:962202072805390@1606418259908/AlexNet-architecture-This-shows-the-process-to-obtain-the-latent-feature-vector-we-use.png)\n",
        "\n",
        "\n",
        "Para los curiosos se recomienda revisar los siguientes links:\n",
        "\n",
        "- Artículo: [Understand Deep Residual Networks](https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624)\n",
        "- [Keras applications](https://keras.io/applications/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVP5RCTpmP7T"
      },
      "source": [
        "# Descarga de imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS0HvidxiYI6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!gdown 1iLOeNZw69iyYXa7QS5ZutN7ACUpkbL3x\n",
        "!unzip images_fashion.zip\n",
        "!mkdir images\n",
        "!mv *.png images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbErfamGmoQ5"
      },
      "source": [
        "# Cargamos la CNN pre-entrenada en ImageNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_gSjumzha4e"
      },
      "outputs": [],
      "source": [
        "# cargamos el modelo escoger\n",
        "\n",
        "modelo_escogido = 'vgg19' #@param[\"vgg16\", \"vgg19\"]\n",
        "\n",
        "if modelo_escogido == 'vgg16':\n",
        "  # cargar modelo\n",
        "  vgg_model = vgg16.VGG16(weights='imagenet')\n",
        "  # quitar la capa de clasificacion\n",
        "  feat_extractor = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer(\"fc2\").output)\n",
        "  # vemos resumen de la arquitectura del modelo\n",
        "  feat_extractor.summary()\n",
        "\n",
        "elif modelo_escogido == 'vgg19':\n",
        "  # cargar modelo\n",
        "  vgg19_model = vgg19.VGG19(weights='imagenet')\n",
        "  # quitar la capa de clasificacion\n",
        "  feat_extractor = Model(inputs=vgg19_model.input, outputs=vgg19_model.get_layer(\"fc2\").output)\n",
        "  # vemos resumen de la arquitectura del modelo\n",
        "  feat_extractor.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TORbe8BXmaoO"
      },
      "source": [
        "## Procesamiento de imágenes para dárselas como input a la CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P_EBGsCCYYY"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujjHhhI-hX4z"
      },
      "outputs": [],
      "source": [
        "imgs_path = \"images/\" # ruta\n",
        "\n",
        "imgs_model_width, imgs_model_height = 224, 224 # tamaño de las imagenes 224x224 pixeles\n",
        "\n",
        "nb_closest_images = 5 # cantidad de imagenes similares a recomendar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlTm43ezha7l"
      },
      "outputs": [],
      "source": [
        "files = [imgs_path + x for x in os.listdir(imgs_path) if \"png\" in x]\n",
        "print(\"total de imagenes:\",len(files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgXqOTkaha_R"
      },
      "outputs": [],
      "source": [
        "# vemos imagen aleatoria\n",
        "import random\n",
        "\n",
        "idx =  random.randint(0, len(files))\n",
        "original = load_img(files[idx], target_size=(imgs_model_width, imgs_model_height))\n",
        "plt.imshow(original)\n",
        "plt.show()\n",
        "print(\"image cargada exitosamente!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5_Y1IrEhkYC"
      },
      "outputs": [],
      "source": [
        "# convertir PIL image a numpy array\n",
        "numpy_image = img_to_array(original)\n",
        "\n",
        "# convertir imagen a batch de imagenes para entrenamiento más eficiente\n",
        "image_batch = np.expand_dims(numpy_image, axis=0)\n",
        "print('image batch size', image_batch.shape)\n",
        "\n",
        "# preparamos la imagen para la VGG16\n",
        "processed_image = preprocess_input(image_batch.copy())\n",
        "\n",
        "processed_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebMGRR7-hnJ5"
      },
      "outputs": [],
      "source": [
        "# obtenemos los features (embeddings) de las imagenes pasandolas por la VGG16\n",
        "img_features = feat_extractor.predict(processed_image)\n",
        "\n",
        "print(\"features successfully extracted!\")\n",
        "print(\"number of image features:\",img_features.size)\n",
        "img_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D95AVVYDTCm"
      },
      "outputs": [],
      "source": [
        "img_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcPsE4GOhp5t"
      },
      "outputs": [],
      "source": [
        "# repetimos el mismo proceso para todas las imagenes y guardamos los batch en una lista para entregarselos procesados a la VGG16\n",
        "importedImages = []\n",
        "\n",
        "for f in files:\n",
        "    filename = f\n",
        "    original = load_img(filename, target_size=(224, 224))\n",
        "    numpy_image = img_to_array(original)\n",
        "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
        "\n",
        "    importedImages.append(image_batch)\n",
        "\n",
        "images = np.vstack(importedImages)\n",
        "\n",
        "processed_imgs = preprocess_input(images.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WhojCf2hsfF"
      },
      "outputs": [],
      "source": [
        "# obtenemos los features para cada imagen con la CNN\n",
        "imgs_features = feat_extractor.predict(processed_imgs)\n",
        "\n",
        "print(\"features extraidos exitosamente!\")\n",
        "imgs_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1Z49Mb-hvqe"
      },
      "outputs": [],
      "source": [
        "# computa similaridad coseno entre los features de las imagenes\n",
        "cosSimilarities = cosine_similarity(imgs_features)\n",
        "\n",
        "# guardamos los resultados en un dataframe\n",
        "cos_similarities_df = pd.DataFrame(cosSimilarities, columns=files, index=files)\n",
        "cos_similarities_df #.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW9_G25thytQ"
      },
      "outputs": [],
      "source": [
        "# esta funcion recupera las imagenes más similares dada una imagen entregada por el usuario\n",
        "def retrieve_most_similar_products(given_img):\n",
        "\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    print(\"producto escogido:\")\n",
        "\n",
        "    original = load_img(given_img, target_size=(imgs_model_width, imgs_model_height))\n",
        "    plt.imshow(original)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    print(\"productos más similares:\")\n",
        "\n",
        "    closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1].index\n",
        "    closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1]\n",
        "\n",
        "    for i in range(0,len(closest_imgs)):\n",
        "        original = load_img(closest_imgs[i], target_size=(imgs_model_width, imgs_model_height))\n",
        "        plt.imshow(original)\n",
        "        plt.show()\n",
        "        print(\"score de similaridad : \",closest_imgs_scores[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbLVqCgxDzB_"
      },
      "outputs": [],
      "source": [
        "idx = 1100 # random.randint(0, len(files))\n",
        "print(idx)\n",
        "print(files[idx])\n",
        "retrieve_most_similar_products(files[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIcl-BWtuqvR"
      },
      "source": [
        "# ACTIVIDAD\n",
        "\n",
        "1. Mostrar 2 ejemplos de búsqueda de imagenes similares utilizando ambas arquitecturas (VGG16 y VGG19) e imprimir los resultados. (3 ptos)\n",
        "\n",
        "2. ¿Cuál de las dos arquitecturas (VGG16 o VGG19) tiene más parámetros entrenables después de quitar la última capa de clasificación?. Justifique indicando la cantidad de parámetros de cada una. (2 ptos)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFxdWAqJFcHv"
      },
      "source": [
        "Pregunta 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zsCbS9gFNzE"
      },
      "source": [
        "VGG 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JRkyQq90RnN"
      },
      "outputs": [],
      "source": [
        "# busqueda 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg-yoHjrFt1E"
      },
      "outputs": [],
      "source": [
        "# busqueda 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW3mYoxiFP_t"
      },
      "source": [
        "VGG 19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrcDJuqJFKA5"
      },
      "outputs": [],
      "source": [
        "# busqueda 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxBNyRQyFKD-"
      },
      "outputs": [],
      "source": [
        "# busqueda 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd1A05bxF6mh"
      },
      "source": [
        "Pregunta 2\n",
        "- parámetros entrenables VGG16 sin última capa\n",
        "- parámetros entrenables VGG19 sin última capa\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUYv2Ez4GIDI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
